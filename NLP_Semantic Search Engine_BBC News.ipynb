{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0316313e",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Keyword-based search engines are easy to use and work well in most scenarios. However, they usually struggle with complex or long queries and words that have a dual meaning. Semantic (also called vector-based) search engines tackle those pitfalls by finding a numerical representation of text queries using state-of-the-art language models, indexing them in a high-dimensional vector space and measuring how similar a query vector is to the indexed documents.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e20e90",
   "metadata": {},
   "source": [
    "We will build semantic search engines using cosine similarity to retrieve news based on a sentence. cosine similarity is the most common metric used to calculate the similarity between document text from input keywords/sentences. The model will match what we write with a news database and suggest the top five news. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195885d0",
   "metadata": {},
   "source": [
    "## Dataset: BBC\n",
    "All rights, including copyright, in the content of the original articles are owned by the BBC.\n",
    "\n",
    "- Consists of 2225 documents from the BBC news website corresponding to stories in five topical areas from 2004-2005.\n",
    "- Class Labels: 5 (business, entertainment, politics, sport, tech)\n",
    "\n",
    "Data Source: http://mlg.ucd.ie/datasets/bbc.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3354287c",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ac66813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1124f935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2225, 2)\n",
      "(2225, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleId</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1833</td>\n",
       "      <td>worldcom ex-boss launches defence lawyers defe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>154</td>\n",
       "      <td>german business confidence slides german busin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1101</td>\n",
       "      <td>bbc poll indicates economic gloom citizens in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1976</td>\n",
       "      <td>lifestyle  governs mobile choice  faster  bett...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>917</td>\n",
       "      <td>enron bosses in $168m payout eighteen former e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ArticleId                                               Text\n",
       "0       1833  worldcom ex-boss launches defence lawyers defe...\n",
       "1        154  german business confidence slides german busin...\n",
       "2       1101  bbc poll indicates economic gloom citizens in ...\n",
       "3       1976  lifestyle  governs mobile choice  faster  bett...\n",
       "4        917  enron bosses in $168m payout eighteen former e..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data set\n",
    "df = pd.read_csv('BBC News Train.csv', usecols = ['ArticleId','Text'])\n",
    "df1 = pd.read_csv('BBC News Test.csv', usecols = ['ArticleId','Text'])\n",
    "newdf = pd.concat([df, df1], ignore_index=True)\n",
    "\n",
    "print(newdf.shape)\n",
    "newdf = newdf[newdf['Text'].notnull()]\n",
    "print(newdf.shape)\n",
    "newdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50671eae",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86756b1a",
   "metadata": {},
   "source": [
    "- Get rid of stopwords such as 'a', 'the', 'is', etc. which are not informative first\n",
    "- Make all the letters lowercase\n",
    "- Remove any funky characters with a blank\n",
    "- Remove inflectional endings to only return the base or dictionary form of a word (Lemmatization)\n",
    "- Use the tokenizer to take a given sentence and parse it into a list with individual words separated by a comma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2ad07be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\newbm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# let's remove some of the stop words\n",
    "nltk.download('stopwords') # download stopwords\n",
    "\n",
    "stopwords_eng = stopwords.words('english')\n",
    "minlen = 4\n",
    "maxlen = 500\n",
    "\n",
    "def clean_text(text):\n",
    "    ''' Pre process and convert texts to a list of words '''\n",
    "    # convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Clean the text\n",
    "    text = re.sub(r\"\\\\r\\\\n\", \" \", text)\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"-\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
    "    text = re.sub(r\"\\+\", \" + \", text)\n",
    "    text = re.sub(r\"\\-\", \" - \", text)\n",
    "    text = re.sub(r\"\\=\", \" = \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
    "    text = re.sub(r\":\", \" : \", text)\n",
    "    text = text.strip()\n",
    "    words = [word for word in text.split() if word not in stopwords_eng]\n",
    "    text = \" \".join(words)\n",
    "    return text\n",
    "\n",
    "def tokenizer(sentence, min_words=minlen, max_words=maxlen, stopwords=stopwords_eng, lemmatize=True):\n",
    "    if lemmatize:\n",
    "        stemmer = WordNetLemmatizer()\n",
    "        tokens = [stemmer.lemmatize(w) for w in word_tokenize(sentence)]\n",
    "    else:\n",
    "        tokens = [w for w in word_tokenize(sentence)]\n",
    "    token = [w for w in tokens if (len(w) > min_words and len(w) < max_words\n",
    "                                                        and w not in stopwords)]\n",
    "    return tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "decb7124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [worldcom, ex, bos, launch, defence, lawyer, d...\n",
       "1       [german, business, confidence, slide, german, ...\n",
       "2       [bbc, poll, indicates, economic, gloom, citize...\n",
       "3       [lifestyle, governs, mobile, choice, faster, b...\n",
       "4       [enron, boss, 168m, payout, eighteen, former, ...\n",
       "                              ...                        \n",
       "2220    [eu, probe, alitalia, state, aid, european, co...\n",
       "2221    [u2, play, grammy, award, show, irish, rock, b...\n",
       "2222    [sport, betting, rule, spotlight, group, mp, p...\n",
       "2223    [alfa, romeo, get, gm, engine, fiat, stop, mak...\n",
       "2224    [citizenship, event, 18, touted, citizenship, ...\n",
       "Name: token_text, Length: 2225, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the results\n",
    "newdf['clean_text'] = newdf['Text'].apply(clean_text)\n",
    "newdf['token_text'] = newdf['clean_text'].apply(tokenizer)\n",
    "newdf['token_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc65a0b",
   "metadata": {},
   "source": [
    "# Semantic Search Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7324c1fe",
   "metadata": {},
   "source": [
    "## TF-IDF\n",
    "\n",
    "TF-IDF is a technique to calculate the weight of each word signifies the importance of the word in the document and corpus. This algorithm is mostly using for the retrieval of information and text mining field.\n",
    "\n",
    "- TF-IDF = Term Frequency (TF) * Inverse Document Frequency (IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6da89a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\newbm\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'could', 'doe', 'ha', 'might', 'must', \"n't\", 'need', 'sha', 'wa', 'wo', 'would'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2225, 26258)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "vectorizer = TfidfVectorizer(stop_words=stopwords_eng, tokenizer=tokenizer) \n",
    "tfidf_mat = vectorizer.fit_transform(newdf['clean_text'].values) # -> (num_sentences, num_vocabulary)\n",
    "tfidf_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2700ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_tfidf(sentence):\n",
    "    \n",
    "    \"\"\"\n",
    "    Return the database sentences in order of highest cosine similarity relatively to each \n",
    "    token of the target sentence. \n",
    "    \"\"\"\n",
    "    # Embed the query sentence\n",
    "    tokens = [str(tok) for tok in tokenizer(sentence)]\n",
    "    vec = vectorizer.transform(tokens)\n",
    "    # Create list with similarity between query and dataset\n",
    "    mat = cosine_similarity(vec, tfidf_mat)\n",
    "    \n",
    "    cos_sim = np.mean(mat, axis=0)\n",
    "    index = np.argsort(cos_sim)[::-1] # from highest idx to smallest score \n",
    "    mask = np.ones(len(cos_sim))\n",
    "    mask = np.logical_or(cos_sim[index] != 0, mask) #eliminate 0 cosine distance\n",
    "    best_index = index[mask][:5]  \n",
    "    return display(newdf[['ArticleId', 'Text']].iloc[best_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a28c792",
   "metadata": {},
   "source": [
    "## Word2Vec\n",
    "\n",
    "Word embedding is one of the most popular representation of document vocabulary. It is capable of capturing context of a word in a document, semantic and syntactic similarity, relation with other words, etc. Word2Vec is one of the most popular technique to learn word embeddings using shallow neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca4562e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14870179, 15225510)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "dataset = newdf['token_text']\n",
    "word2vec_model = Word2Vec(min_count=0, workers = 8, vector_size=300) \n",
    "word2vec_model.build_vocab(dataset.values)\n",
    "word2vec_model.train(dataset.values, total_examples=word2vec_model.corpus_count, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e4b94a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = newdf['token_text']\n",
    "\n",
    "def is_word_in_model(word, model):\n",
    "    \"\"\"\n",
    "    Check on individual words ``word`` that it exists in ``model``.\n",
    "    \"\"\"\n",
    "    assert type(model).__name__ == 'KeyedVectors'\n",
    "    is_in_vocab = word in model.key_to_index.keys()\n",
    "    return is_in_vocab\n",
    "\n",
    "def search_w2v(query_sentence, topk=5):\n",
    "    \n",
    "    query_sentence = query_sentence.split()\n",
    "    in_vocab_list, best_index = [], [0]*topk\n",
    "    for w in query_sentence:\n",
    "        # remove unseen words from query sentence\n",
    "        if is_word_in_model(w, word2vec_model.wv):\n",
    "            in_vocab_list.append(w)\n",
    "    # Retrieve the similarity between two words as a distance\n",
    "    if len(in_vocab_list) > 0:\n",
    "        sim_mat = np.zeros(len(dataset))  # TO DO\n",
    "        for i, data_sentence in enumerate(dataset):\n",
    "            if data_sentence:\n",
    "                sim_sentence = word2vec_model.wv.n_similarity(\n",
    "                        in_vocab_list, data_sentence)\n",
    "            else:\n",
    "                sim_sentence = 0\n",
    "            sim_mat[i] = np.array(sim_sentence)\n",
    "        # Take the five highest norm\n",
    "        best_index = np.argsort(sim_mat)[::-1][:topk]\n",
    "    return display(newdf[['ArticleId', 'Text']].iloc[best_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891f7473",
   "metadata": {},
   "source": [
    "## SentenceTransformers\n",
    "\n",
    "SentenceTransformers is a Python framework for state-of-the-art sentence, text and image embeddings. We can use this framework to compute sentence / text embeddings for more than 100 languages. These embeddings can then be compared with cosine-similarity to find sentences with a similar meaning. This can be useful for semantic textual similar, semantic search, or paraphrase mining. Here, we will use a 'paraphrase-MiniLM-L6-v2' model which performs great in Semantic Textual Similarity tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa989dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_transformers(query_sentence):\n",
    "    model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "    corpus_embeddings = model.encode(newdf['clean_text'].values, convert_to_tensor=True)\n",
    "    query_embedding = model.encode(query_sentence, convert_to_tensor=True)\n",
    "    \n",
    "    # We use cosine-similarity and torch.topk to find the highest 5 scores\n",
    "    cos_scores = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]\n",
    "    top_results = torch.topk(cos_scores, k=5)\n",
    "\n",
    "    for score, idx in zip(top_results[0], top_results[1]):\n",
    "        score = score.cpu().data.numpy() \n",
    "        idx = idx.cpu().data.numpy()\n",
    "        print(newdf[['ArticleId', 'Text']].iloc[idx])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9e681a",
   "metadata": {},
   "source": [
    "# Search for news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d733cdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_sentence = \"2004 Indian Ocean earthquake and tsunami\" \n",
    "\n",
    "pd.options.display.max_colwidth = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c52196bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleId</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>1790</td>\n",
       "      <td>us tv special for tsunami relief a us television network will screen a celebrity tv special to benefit the tsunami relief effort in south asia.  nbc will encourage viewer donations during an hour-long show featuring musical performances on 15 january. actress sandra bullock has donated $1m (£525 000) to the american red cross and actor leonardo dicaprio pledged a  sizable  aid contribution to unicef. meanwhile 70 hong kong music and movie stars re-recorded we are the world in mandarin and ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2071</th>\n",
       "      <td>837</td>\n",
       "      <td>tsunami cost hits jakarta shares the stock market in jakarta has seen its biggest slide in a month  after the country doubled the likely cost of rebuilding from the asian tsunami.  the fall came as indonesia said it expected debt repayments of up to 30 trillion rupiah ($3.2bn; £1.7bn) to be frozen to help pay for the recovery. by monday s close  the jakarta stock exchange was down 2.1% at 1 011.15. bar a slight dip at the new year  the jse had risen steadily by 4.7% since the tsunami hit on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>1677</td>\n",
       "      <td>gurkhas to help tsunami victims britain has offered to send a company of 120 gurkhas to assist with the tsunami relief effort in indonesia  downing street said.  the deployment would involve troops from the 2nd battalion royal gurkha rifles  based in brunei. discussions have begun with indonesia on the exact timing and location of the deployment  but the government said the offer was aimed at the aceh province. downing st said a similar offer might be made to the sri lankan government.  howe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2140</th>\n",
       "      <td>5</td>\n",
       "      <td>ocean s twelve raids box office ocean s twelve  the crime caper sequel starring george clooney  brad pitt and julia roberts  has gone straight to number one in the us box office chart.  it took $40.8m (£21m) in weekend ticket sales  according to studio estimates. the sequel follows the master criminals as they try to pull off three major heists across europe. it knocked last week s number one  national treasure  into third place. wesley snipes  blade: trinity was in second  taking $16.1m (£8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1391</th>\n",
       "      <td>1854</td>\n",
       "      <td>ocean s twelve raids box office ocean s twelve  the crime caper sequel starring george clooney  brad pitt and julia roberts  has gone straight to number one in the us box office chart.  it took $40.8m (£21m) in weekend ticket sales  according to studio estimates. the sequel follows the master criminals as they try to pull off three major heists across europe. it knocked last week s number one  national treasure  into third place. wesley snipes  blade: trinity was in second  taking $16.1m (£8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ArticleId  \\\n",
       "1017       1790   \n",
       "2071        837   \n",
       "894        1677   \n",
       "2140          5   \n",
       "1391       1854   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Text  \n",
       "1017  us tv special for tsunami relief a us television network will screen a celebrity tv special to benefit the tsunami relief effort in south asia.  nbc will encourage viewer donations during an hour-long show featuring musical performances on 15 january. actress sandra bullock has donated $1m (£525 000) to the american red cross and actor leonardo dicaprio pledged a  sizable  aid contribution to unicef. meanwhile 70 hong kong music and movie stars re-recorded we are the world in mandarin and ca...  \n",
       "2071  tsunami cost hits jakarta shares the stock market in jakarta has seen its biggest slide in a month  after the country doubled the likely cost of rebuilding from the asian tsunami.  the fall came as indonesia said it expected debt repayments of up to 30 trillion rupiah ($3.2bn; £1.7bn) to be frozen to help pay for the recovery. by monday s close  the jakarta stock exchange was down 2.1% at 1 011.15. bar a slight dip at the new year  the jse had risen steadily by 4.7% since the tsunami hit on ...  \n",
       "894   gurkhas to help tsunami victims britain has offered to send a company of 120 gurkhas to assist with the tsunami relief effort in indonesia  downing street said.  the deployment would involve troops from the 2nd battalion royal gurkha rifles  based in brunei. discussions have begun with indonesia on the exact timing and location of the deployment  but the government said the offer was aimed at the aceh province. downing st said a similar offer might be made to the sri lankan government.  howe...  \n",
       "2140  ocean s twelve raids box office ocean s twelve  the crime caper sequel starring george clooney  brad pitt and julia roberts  has gone straight to number one in the us box office chart.  it took $40.8m (£21m) in weekend ticket sales  according to studio estimates. the sequel follows the master criminals as they try to pull off three major heists across europe. it knocked last week s number one  national treasure  into third place. wesley snipes  blade: trinity was in second  taking $16.1m (£8...  \n",
       "1391  ocean s twelve raids box office ocean s twelve  the crime caper sequel starring george clooney  brad pitt and julia roberts  has gone straight to number one in the us box office chart.  it took $40.8m (£21m) in weekend ticket sales  according to studio estimates. the sequel follows the master criminals as they try to pull off three major heists across europe. it knocked last week s number one  national treasure  into third place. wesley snipes  blade: trinity was in second  taking $16.1m (£8...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TF-IDF\n",
    "search_tfidf(query_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df93e6ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleId</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1175</th>\n",
       "      <td>1117</td>\n",
       "      <td>stormy year for property insurers a string of storms  typhoons and earthquakes has made 2004 the most expensive year on record for property insurers  according to swiss re.  the world s second biggest insurer said disasters around the globe have seen property claims reach $42bn (£21.5bn).  2004 reinforces the trend towards higher losses   said swiss re. tightly packed populations in the areas involved in natural and man-made disasters were to partly to blame for the rise in claims  it said. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>1790</td>\n",
       "      <td>us tv special for tsunami relief a us television network will screen a celebrity tv special to benefit the tsunami relief effort in south asia.  nbc will encourage viewer donations during an hour-long show featuring musical performances on 15 january. actress sandra bullock has donated $1m (£525 000) to the american red cross and actor leonardo dicaprio pledged a  sizable  aid contribution to unicef. meanwhile 70 hong kong music and movie stars re-recorded we are the world in mandarin and ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2133</th>\n",
       "      <td>243</td>\n",
       "      <td>china now top trader with japan china overtook the us to become japan s biggest trading partner in 2004  according to numbers released by japan s finance ministry on wednesday.  china accounted for 20.1% of japan s trade in 2004  compared with 18.6% for the us. in 2003  the us was ahead with 20.5% and china came second with 19.2%. the change highlights china s growing importance as an economic powerhouse. in 2004  japan s imports from and exports to china (and hong kong) added up to 22 201bn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>766</td>\n",
       "      <td>lufthansa flies back to profit german airline lufthansa has returned to profit in 2004 after posting huge losses in 2003.  in a preliminary report  the airline announced net profits of 400m euros ($527.61m; £274.73m)  compared with a loss of 984m euros in 2003. operating profits were at 380m euros  ten times more than in 2003. lufthansa was hit in 2003 by tough competition and a dip in demand following the iraq war and the killer sars virus. it was also hit by troubles at its us catering bus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2071</th>\n",
       "      <td>837</td>\n",
       "      <td>tsunami cost hits jakarta shares the stock market in jakarta has seen its biggest slide in a month  after the country doubled the likely cost of rebuilding from the asian tsunami.  the fall came as indonesia said it expected debt repayments of up to 30 trillion rupiah ($3.2bn; £1.7bn) to be frozen to help pay for the recovery. by monday s close  the jakarta stock exchange was down 2.1% at 1 011.15. bar a slight dip at the new year  the jse had risen steadily by 4.7% since the tsunami hit on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ArticleId  \\\n",
       "1175       1117   \n",
       "1017       1790   \n",
       "2133        243   \n",
       "677         766   \n",
       "2071        837   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Text  \n",
       "1175  stormy year for property insurers a string of storms  typhoons and earthquakes has made 2004 the most expensive year on record for property insurers  according to swiss re.  the world s second biggest insurer said disasters around the globe have seen property claims reach $42bn (£21.5bn).  2004 reinforces the trend towards higher losses   said swiss re. tightly packed populations in the areas involved in natural and man-made disasters were to partly to blame for the rise in claims  it said. ...  \n",
       "1017  us tv special for tsunami relief a us television network will screen a celebrity tv special to benefit the tsunami relief effort in south asia.  nbc will encourage viewer donations during an hour-long show featuring musical performances on 15 january. actress sandra bullock has donated $1m (£525 000) to the american red cross and actor leonardo dicaprio pledged a  sizable  aid contribution to unicef. meanwhile 70 hong kong music and movie stars re-recorded we are the world in mandarin and ca...  \n",
       "2133  china now top trader with japan china overtook the us to become japan s biggest trading partner in 2004  according to numbers released by japan s finance ministry on wednesday.  china accounted for 20.1% of japan s trade in 2004  compared with 18.6% for the us. in 2003  the us was ahead with 20.5% and china came second with 19.2%. the change highlights china s growing importance as an economic powerhouse. in 2004  japan s imports from and exports to china (and hong kong) added up to 22 201bn...  \n",
       "677   lufthansa flies back to profit german airline lufthansa has returned to profit in 2004 after posting huge losses in 2003.  in a preliminary report  the airline announced net profits of 400m euros ($527.61m; £274.73m)  compared with a loss of 984m euros in 2003. operating profits were at 380m euros  ten times more than in 2003. lufthansa was hit in 2003 by tough competition and a dip in demand following the iraq war and the killer sars virus. it was also hit by troubles at its us catering bus...  \n",
       "2071  tsunami cost hits jakarta shares the stock market in jakarta has seen its biggest slide in a month  after the country doubled the likely cost of rebuilding from the asian tsunami.  the fall came as indonesia said it expected debt repayments of up to 30 trillion rupiah ($3.2bn; £1.7bn) to be frozen to help pay for the recovery. by monday s close  the jakarta stock exchange was down 2.1% at 1 011.15. bar a slight dip at the new year  the jse had risen steadily by 4.7% since the tsunami hit on ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Word2Vec\n",
    "search_w2v(query_sentence) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "675a1c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ArticleId                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   1485\n",
      "Text         tsunami to cost sri lanka $1.3bn sri lanka faces a $1.3bn (£691m) bill in 2005 for reconstruction after the tsunami which killed more than 30 000 of its people  its central bank says.  this estimate is preliminary  bank governor sunil mendis told reporters  and could rise in 2006. the island state is asking for about $320m from the international monetary fund to help pay for relief  he said. the bank has 5bn rupees ($50m; £27m) set aside to lend at a lower interest rate to those who lost pro...\n",
      "Name: 1197, dtype: object\n",
      "ArticleId                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   1118\n",
      "Text         tsunami slows sri lanka s growth sri lanka s president has launched a reconstruction drive worth $3.5bn (£1.8bn) by appealing for peace and national unity.  president kumaratunga said it was now important to find a peaceful solution to years of internal conflict. meanwhile  the international monetary fund (imf) said damage from the tsunami would cut one percentage point from sri lanka s economic growth this year. it estimated the wave left physical damage equal to 6.5% of the economy.  separ...\n",
      "Name: 1276, dtype: object\n",
      "ArticleId                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   1790\n",
      "Text         us tv special for tsunami relief a us television network will screen a celebrity tv special to benefit the tsunami relief effort in south asia.  nbc will encourage viewer donations during an hour-long show featuring musical performances on 15 january. actress sandra bullock has donated $1m (£525 000) to the american red cross and actor leonardo dicaprio pledged a  sizable  aid contribution to unicef. meanwhile 70 hong kong music and movie stars re-recorded we are the world in mandarin and ca...\n",
      "Name: 1017, dtype: object\n",
      "ArticleId                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    837\n",
      "Text         tsunami cost hits jakarta shares the stock market in jakarta has seen its biggest slide in a month  after the country doubled the likely cost of rebuilding from the asian tsunami.  the fall came as indonesia said it expected debt repayments of up to 30 trillion rupiah ($3.2bn; £1.7bn) to be frozen to help pay for the recovery. by monday s close  the jakarta stock exchange was down 2.1% at 1 011.15. bar a slight dip at the new year  the jse had risen steadily by 4.7% since the tsunami hit on ...\n",
      "Name: 2071, dtype: object\n",
      "ArticleId                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   1231\n",
      "Text         asia quake increases poverty risk nearly two million people across asia could be thrown into poverty because of the indian ocean tsunami  the asian development bank (adb) has said.  in its first overview of the disaster  the adb said the impact on economic growth would be slight because major cities and factories escaped damage. but the blow to many low-income people could be  enormous . the paris club of rich creditor nations on wednesday offered to freeze debts owed by tsunami-hit countrie...\n",
      "Name: 1312, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# SentenceTransformers\n",
    "search_transformers(query_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4813fe",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "We built semantic search engines using TF-IDF, Word2Vec, and Sentence Transformers to retrieve the top-5 closest news from the dataset that match this query sentence. It seems that the transformer model performs best while it takes a longer time. However, picking the best model can be subjective, so A/B tests are needed based on click-through rates and session durations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
